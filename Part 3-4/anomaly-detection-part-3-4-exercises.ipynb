{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6679bc",
   "metadata": {},
   "source": [
    "## ANOMALY DETECTION PART 3 EXERCISE  ##\n",
    "#### Exercise 1 ####\n",
    "#### Task 1\n",
    "##### Import the required packages\n",
    "##### Set the working directory to data directory\n",
    "##### Print the working directory and the plot directory\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d9681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca5c5bd1",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Read in `seismic-hazards.csv` to a new dataframe `hazard`.\n",
    "##### Read the documentation to understand the variables https://archive.ics.uci.edu/ml/datasets/seismic-bumps#\n",
    "##### Explore the dataset by printing its head, info and shape.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec1f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ea99251",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Drop all the non-numerical and id columns - `['seismic','seismoacoustic','shift','ghazard','id']` \n",
    "##### Save this subset as `hazard_sub` and print its head.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1270b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a82112",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Split the subset to train and test.\n",
    "##### Now split the train dataset to `hazard` (class `1`) which has all outlier data and `non_hazard` (class `0`) which has all regular observations.\n",
    "##### Drop `class` variable from `non_hazard` dataframe.\n",
    "##### Append test dataset with `hazard`. Save the `class` variable from test as `actual_test`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cb1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d69dec21",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Instantiate a LOF with `n_neighbors` set to `5`, `contamination = 0.1` and `novelty = True` to `non_hazard`\n",
    "##### Fit the model with `non_hazard` data.\n",
    "##### Predict on hazard `test` and print first 5 predictions. \n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28daa88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92ba9807",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Map the values to `0` for non-anomalies and `1` for anomalies.\n",
    "##### Evalulate the model by finding the TPR and TNR\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab1c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "570a1bfa",
   "metadata": {},
   "source": [
    "#### Exercise 2 ####\n",
    "#### Task 1\n",
    "##### Tune the neighborhood size and find the optimal n_neighbors parameter for the LOF model  \n",
    "##### Plot the TPR and TNR for the range of neighborhood sizes used\n",
    "##### Find the optimal n_neighbor parameter from the plot\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3ebd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc456bf9",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Tune the contamination and find the optimal contamination parameter for the LOF model.\n",
    "##### Plot the TPR and TNR for the all the contamination values used.\n",
    "##### Find the optimal contamination parameter from the plot.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c99fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bcb3e28",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Fit the LOF model with the optimal parameters\n",
    "##### Evaluate this model by finding the TPR and TNR on hazard test dataset\n",
    "##### Load the `ex_performance_anomalies.sav` pickle file from the data folder and the scores of the LOF model\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b430f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9111912",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Save `performance_df_ex`, `non_hazard`, `test` and `actual_test` as pickle files `ex_performance_anomalies.sav`, `non_hazard.sav`, `test.sav` and `actual_test.sav` respectively for the following exercises.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94fe46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f64cdc67",
   "metadata": {},
   "source": [
    "## ANOMALY DETECTION PART 4 EXERCISE  ##\n",
    "#### Exercise 3 ####\n",
    "#### Task 1\n",
    "##### Import the required packages\n",
    "##### Set the working directory to data directory\n",
    "##### Print the working directory and the plot directory\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e95823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ae1669c",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "##### Load pickled files from the previous exercises `ex_performance_anomalies.sav`, `non_hazard.sav`, `test.sav` and `actual_test.sav` as `performance_df_ex`, `non_hazard`, `test` and `actual_test` respectively.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbae48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b961c1b4",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Load `PJM_Load_hourly.csv` dataset and print the head. Save as `pjm_load`.\n",
    "##### Convert `Datatime` variable from type `object` to `datetime`. Check its datatype after type-conversion\n",
    "##### Filter the data to include values post year 2000\n",
    "##### Visualize the timeseries data using a lineplot\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b0085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f0ada7",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Fit the LOF model with `n_neighbors: 100` , `contamination: 0.01`  and `novelty: False`\n",
    "##### Predict for anomalies for the variable `PJM_Load_MW` and save the results in the pjm_load dataframe\n",
    "##### Visualize the detected anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b03427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd5ca480",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Create variable `lof_upper_anomalies` that has the upper range of anomalies detected using the 75% quantile threshold\n",
    "##### Create variable `lof_lower_anomalies` that has the lower range of anomalies detected using the 25% quantile threshold\n",
    "##### Visualize `lof_upper_anomalies` and `lof_lower_anomalies`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef93c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0775677",
   "metadata": {},
   "source": [
    "#### Exercise 4 ####\n",
    "#### Task 1\n",
    "##### Fit an isolation forest with 100 estimators and contamination: 0.1\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f0834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a98f48e",
   "metadata": {},
   "source": [
    "#### Task 2 \n",
    "##### Predict on hazard test data and map the predictions as 0 for non-anomalies and 1 for anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9847107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e3f374",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Evaluate the model using TPR and TNR\n",
    "##### Append the scores to the `performance_df_ex` dataframe\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025daac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3356da11",
   "metadata": {},
   "source": [
    "#### Exercise 5 ####\n",
    "#### Task 1\n",
    "##### Fit an isolation forest with 100 estimators and contamination: 0.01 on `pjm_load` time series data\n",
    "##### Predict for anomalies on `PJM_Load_MW` variable and save the results as a column in the pjm_load dataframe\n",
    "##### Visualize the detected anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "849345d1",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Create variable `if_upper_anomalies` that has the upper range of anomalies detected using the 75% quantile threshold\n",
    "##### Create variable `if_lower_anomalies` that has the lower range of anomalies detected using the 25% quantile threshold\n",
    "##### Visualize `if_upper_anomalies` and `if_lower_anomalies`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2b3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c8a615c",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Compare the anomalies detected from LOF and Isolation Forest\n",
    "##### Create a comparison plot for the lower range of anomalies\n",
    "##### Create a comparison plot for the upper range of anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670d875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dcb86d9",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Save the `performance_df_ex` as a pickle file `ex_performance_anomalies.sav`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd00357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
