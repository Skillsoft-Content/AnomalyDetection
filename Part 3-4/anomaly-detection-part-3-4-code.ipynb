{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## ANOMALY DETECTION PART 3 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 26: Loading packages  ####\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc775d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 27: Directory settings  ####\n",
    "\n",
    "# Set 'main_dir' to location of the project folder\n",
    "from pathlib import Path \n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 28: Load the dataset  ####\n",
    "\n",
    "paysim = pd.read_csv(str(data_dir)+\"/paysim_transactions.csv\")\n",
    "paysim.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 29: Prepare the dataset for modeling  ####\n",
    "\n",
    "# Drop columns. \n",
    "paysim = paysim.drop(['step', 'type','nameOrig', 'nameDest', 'isFlaggedFraud'], axis = 1)\n",
    "paysim.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================= -\n",
    "#### Slide 30: LOF on fraud dataset  ####\n",
    "\n",
    "train, test = train_test_split(paysim, test_size=.30)\n",
    "\n",
    "# Split fraud vs non fraud.\n",
    "non_fraud = train[train['isFraud']==0] \n",
    "fraud = train[train['isFraud']==1]\n",
    "non_fraud = non_fraud.drop(['isFraud'], axis = 1)\n",
    "\n",
    "test = test.append(fraud)\n",
    "actual_test = test['isFraud']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320745e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 31: Create and fit LOF model  ####\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors = 5, \n",
    "                         metric = \"manhattan\", \n",
    "                         contamination = 0.1, \n",
    "                         novelty = True)\n",
    "\n",
    "# model fitting\n",
    "lof.fit(non_fraud)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ad43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 32: Test predictions  ####\n",
    "\n",
    "fraud_pred = lof.predict(test.iloc[:,:-1])\n",
    "fraud_pred\n",
    "fraud_pred[fraud_pred == 1] = 0\n",
    "fraud_pred[fraud_pred == -1] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================= -\n",
    "#### Slide 33: Find TPR and TNR  ####\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(actual_test, fraud_pred).ravel()\n",
    "non_fraud_eval = tn / (tn + fp)\n",
    "print(non_fraud_eval)\n",
    "fraud_eval = tp / (tp + fn)\n",
    "print(fraud_eval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================= -\n",
    "#### Slide 41: Optimized LOF model  ####\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors = 10, \n",
    "                         metric = \"manhattan\", \n",
    "                         contamination = 0.1, \n",
    "                         novelty = True)\n",
    "\n",
    "# model fitting\n",
    "lof.fit(non_fraud)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 42: Test predictions  ####\n",
    "\n",
    "fraud_pred = lof.predict(test.iloc[:,:-1])\n",
    "fraud_pred[fraud_pred == 1] = 0\n",
    "fraud_pred[fraud_pred == -1] = 1\n",
    "tn, fp, fn, tp = confusion_matrix(actual_test, fraud_pred).ravel()\n",
    "non_fraud_eval = tn / (tn + fp)\n",
    "print(non_fraud_eval)\n",
    "fraud_eval = tp / (tp + fn)\n",
    "print(fraud_eval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 43: Load performance_df dataframe  ####\n",
    "\n",
    "performance_df = pickle.load(open(str(data_dir)+\"/performance_anomalies.sav\",\"rb\"))  \n",
    "s = pd.Series(['LOF', fraud_eval, non_fraud_eval], \n",
    "              index=['model_name', 'TPR', 'TNR'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d606ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 45: Exercise 2  ####\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 47: Save results as a pickle  ####\n",
    "\n",
    "pickle.dump(non_fraud, open(str(data_dir) + '/non_fraud.sav', 'wb'))\n",
    "pickle.dump(test, open(str(data_dir) + '/test.sav', 'wb'))\n",
    "pickle.dump(actual_test, open(str(data_dir) + '/actual_test.sav', 'wb'))\n",
    "pickle.dump(performance_df, open(str(data_dir) + '/performance_anomalies.sav', 'wb'))\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3826f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## ANOMALY DETECTION PART 4 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 2: Loading packages  ####\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 3: Directory settings  ####\n",
    "\n",
    "# Set 'main_dir' to location of the project folder\n",
    "from pathlib import Path \n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95aaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 4: Load pickled data from previous module  ####\n",
    "\n",
    "non_fraud = pickle.load(open((data_dir + \"/non_fraud.sav\"),\"rb\"))\n",
    "test = pickle.load(open((data_dir + \"/test.sav\"),\"rb\"))\n",
    "actual_test = pickle.load(open((data_dir + \"/actual_test.sav\"),\"rb\"))\n",
    "performance_df = pickle.load(open((data_dir + \"/performance_anomalies.sav\"),\"rb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de55644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 5: Data: load energy consumption  ####\n",
    "\n",
    "pjm_energy = pd.read_csv(str(data_dir)+\"/PJME_hourly.csv\")\n",
    "pjm_energy.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 6: Data: preprocessing  ####\n",
    "\n",
    "pjm_energy['Datetime'] = pd.to_datetime(pjm_energy['Datetime'])\n",
    "pjm_energy.info()\n",
    "pjm_energy = pjm_energy[pjm_energy['Datetime'] > '2018-01-01 00:00:00']\n",
    "pjm_energy.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a153bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 9: Create and fit LOF model: energy consumption  ####\n",
    "\n",
    "lof_energy_model = LocalOutlierFactor(n_neighbors = 50, \n",
    "                                      metric = \"manhattan\", \n",
    "                                      contamination = 0.01, \n",
    "                                      novelty = False)\n",
    "                                      \n",
    "pjm_energy['anomaly'] = lof_energy_model.fit_predict(pd.DataFrame(pjm_energy['PJME_MW']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451bcdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: LOF - visualize anomalies  ####\n",
    "\n",
    "lower_threshold = pjm_energy['PJME_MW'].quantile(0.25)\n",
    "upper_threshold = pjm_energy['PJME_MW'].quantile(0.75)\n",
    "lof_anomalies = pjm_energy[pjm_energy['anomaly'] == -1]\n",
    "# Upper range of anomalies\n",
    "lof_upper_anomalies = lof_anomalies[lof_anomalies['PJME_MW'] > upper_threshold]['PJME_MW']\n",
    "\n",
    "# Lower range of anomalies\n",
    "lof_lower_anomalies = lof_anomalies[lof_anomalies['PJME_MW'] < lower_threshold]['PJME_MW']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2254cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Exercise 3  ####\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66590a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 24: Create and fit isolation forest model  ####\n",
    "\n",
    "iforest = IsolationForest(n_estimators=100, contamination = 0.1)\n",
    "\n",
    "# model fitting\n",
    "iforest.fit(non_fraud)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ec54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 25: Test predictions  ####\n",
    "\n",
    "fraud_pred = iforest.predict(test.iloc[:,:-1])\n",
    "fraud_pred\n",
    "fraud_pred[fraud_pred == 1] = 0\n",
    "fraud_pred[fraud_pred == -1] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eeef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================= -\n",
    "#### Slide 26: Find TPR and TNR  ####\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(actual_test, fraud_pred).ravel()\n",
    "non_fraud_eval = tn / (tn + fp)\n",
    "print(non_fraud_eval)\n",
    "fraud_eval = tp / (tp + fn)\n",
    "print(fraud_eval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981478d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 27: Load performance_df dataframe  ####\n",
    "\n",
    "s = pd.Series(['Isolation Forest', fraud_eval, non_fraud_eval], \n",
    "              index=['model_name', 'TPR', 'TNR'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 30: Exercise 4  ####\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 32: Isolation forest on time series data  ####\n",
    "\n",
    "isolation_energy = IsolationForest(n_estimators=100, contamination = 0.01)\n",
    "\n",
    "# model fitting\n",
    "isolation_energy.fit(pd.DataFrame(pjm_energy['PJME_MW']))\n",
    "pjm_energy['anomaly'] = isolation_energy.predict(pd.DataFrame(pjm_energy['PJME_MW']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Isolation forest - visualize anomalies  ####\n",
    "\n",
    "# visualization\n",
    "lower_threshold = pjm_energy['PJME_MW'].quantile(0.25)\n",
    "upper_threshold = pjm_energy['PJME_MW'].quantile(0.75)\n",
    "if_anomalies = pjm_energy[pjm_energy['anomaly'] == -1]\n",
    "\n",
    "if_upper_anomalies = if_anomalies[if_anomalies['PJME_MW'] > upper_threshold]['PJME_MW']\n",
    "if_lower_anomalies = if_anomalies[if_anomalies['PJME_MW'] < lower_threshold]['PJME_MW']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 37: Exercise 5  ####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n",
    "#######################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
