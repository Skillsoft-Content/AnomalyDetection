{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6679bc",
   "metadata": {},
   "source": [
    "## ANOMALY DETECTION PART 3 EXERCISE ANSWERS ##\n",
    "#### Exercise 1 ####\n",
    "#### Task 1\n",
    "##### Import the required packages\n",
    "##### Set the working directory to data directory\n",
    "##### Print the working directory and the plot directory\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# Set 'main_dir' to location of the project folder\n",
    "from pathlib import Path \n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c5bd1",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Read in `seismic-hazards.csv` to a new dataframe `hazard`.\n",
    "##### Read the documentation to understand the variables https://archive.ics.uci.edu/ml/datasets/seismic-bumps#\n",
    "##### Explore the dataset by printing its head, info and shape.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard = pd.read_csv(str(data_dir)+'/seismic-hazard.csv')\n",
    "hazard.head()\n",
    "hazard.shape\n",
    "hazard.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea99251",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Drop all the non-numerical and id columns - `['seismic','seismoacoustic','shift','ghazard','id']` \n",
    "##### Save this subset as `hazard_sub` and print its head.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1270b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_sub = hazard.drop(['seismic','seismoacoustic','shift','ghazard','id'], axis = 1)\n",
    "hazard_sub.head()\n",
    "hazard_sub['class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a82112",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Split the subset to train and test.\n",
    "##### Now split the train dataset to `hazard` (class `1`) which has all outlier data and `non_hazard` (class `0`) which has all regular observations.\n",
    "##### Drop `class` variable from `non_hazard` dataframe.\n",
    "##### Append test dataset with `hazard`. Save the `class` variable from test as `actual_test`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cb1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(hazard_sub, test_size=.30)\n",
    "# Split hazard vs non hazard.\n",
    "non_hazard = train[train['class']==0] \n",
    "hazard = train[train['class']==1]\n",
    "non_hazard = non_hazard.drop(['class'], axis = 1)\n",
    "test = test.append(hazard)\n",
    "actual_test = test['class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69dec21",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Instantiate a LOF with `n_neighbors` set to `5`, `contamination = 0.1` and `novelty = True` to `non_hazard`\n",
    "##### Fit the model with `non_hazard` data.\n",
    "##### Predict on hazard `test` and print first 5 predictions. \n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28daa88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors = 5, metric = \"manhattan\", contamination = 0.1, novelty = True)\n",
    "# model fitting\n",
    "lof.fit(non_hazard)\n",
    "hazard_pred = lof.predict(test.iloc[:,:-1])\n",
    "hazard_pred[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba9807",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Map the values to `0` for non-anomalies and `1` for anomalies.\n",
    "##### Evalulate the model by finding the TPR and TNR\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_pred[hazard_pred == 1] = 0\n",
    "hazard_pred[hazard_pred == -1] = 1\n",
    "tn, fp, fn, tp = confusion_matrix(actual_test, hazard_pred).ravel()\n",
    "non_hazard_eval = tn / (tn + fp)\n",
    "print(non_hazard_eval)\n",
    "hazard_eval = tp / (tp + fn)\n",
    "print(hazard_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a1bfa",
   "metadata": {},
   "source": [
    "#### Exercise 2 ####\n",
    "#### Task 1\n",
    "##### Tune the neighborhood size and find the optimal n_neighbors parameter for the LOF model  \n",
    "##### Plot the TPR and TNR for the range of neighborhood sizes used\n",
    "##### Find the optimal n_neighbor parameter from the plot\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_df = pd.DataFrame()\n",
    "for neighbor in range(3,21):\n",
    "    lof = LocalOutlierFactor(n_neighbors = neighbor, metric = \"manhattan\", novelty = True)\n",
    "    lof.fit(non_hazard)\n",
    "    hazard_pred = lof.predict(test.iloc[:,:-1])\n",
    "    hazard_pred[hazard_pred == 1] = 0\n",
    "    hazard_pred[hazard_pred == -1] = 1\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_test, hazard_pred).ravel()\n",
    "    non_hazard_eval = tn / (tn + fp)\n",
    "    hazard_eval = tp / (tp + fn)\n",
    "    values  =  [neighbor,non_hazard_eval,hazard_eval]\n",
    "    values = pd.DataFrame(values).T\n",
    "    lof_df = pd.concat([lof_df,values])\n",
    "lof_df.columns=['Neighbor','TNR','TPR']\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(lof_df['Neighbor'],lof_df['TNR'], label = 'TNR')\n",
    "plt.plot(lof_df['Neighbor'],lof_df['TPR'], label = 'TPR')\n",
    "plt.xlabel('Neighbor')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "We see that TPR and TNR are high around 3 neighbors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc456bf9",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Tune the contamination and find the optimal contamination parameter for the LOF model.\n",
    "##### Plot the TPR and TNR for the all the contamination values used.\n",
    "##### Find the optimal contamination parameter from the plot.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c99fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination_values = [0.01,0.03,0.05,0.1,0.2,0.3,0.4,0.5]\n",
    "lof_df = pd.DataFrame()\n",
    "for contamination_value in contamination_values:\n",
    "    lof = LocalOutlierFactor(n_neighbors = 20, metric = \"manhattan\",contamination = contamination_value, novelty = True)\n",
    "    lof.fit(non_hazard)\n",
    "    hazard_pred = lof.predict(test.iloc[:,:-1])\n",
    "    hazard_pred[hazard_pred == 1] = 0\n",
    "    hazard_pred[hazard_pred == -1] = 1\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_test, hazard_pred).ravel()\n",
    "    non_hazard_eval = tn / (tn + fp)\n",
    "    hazard_eval = tp / (tp + fn)\n",
    "    values  =  [contamination_value,non_hazard_eval,hazard_eval]\n",
    "    values = pd.DataFrame(values).T\n",
    "    lof_df = pd.concat([lof_df,values])\n",
    "lof_df.columns=['Contamination','TNR','TPR']\n",
    "plt.plot(lof_df['Contamination'],lof_df['TNR'], label = 'TNR')\n",
    "plt.plot(lof_df['Contamination'],lof_df['TPR'], label = 'TPR')\n",
    "plt.xlabel('Contamination')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "We see that both TPR and TNR are high around 0.2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb3e28",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Fit the LOF model with the optimal parameters\n",
    "##### Evaluate this model by finding the TPR and TNR on hazard test dataset\n",
    "##### Load the `ex_performance_anomalies.sav` pickle file from the data folder and the scores of the LOF model\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b430f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors = 3, metric = \"manhattan\", contamination = 0.2, novelty = True)\n",
    "# model fitting\n",
    "lof.fit(non_hazard)\n",
    "hazard_pred = lof.predict(test.iloc[:,:-1])\n",
    "hazard_pred[hazard_pred == 1] = 0\n",
    "hazard_pred[hazard_pred == -1] = 1\n",
    "tn, fp, fn, tp = confusion_matrix(actual_test, hazard_pred).ravel()\n",
    "non_hazard_eval = tn / (tn + fp)\n",
    "print(non_hazard_eval)\n",
    "hazard_eval = tp / (tp + fn)\n",
    "print(hazard_eval)\n",
    "performance_df_ex = pickle.load(open(str(data_dir) + '/ex_performance_anomalies.sav',\"rb\"))\n",
    "s = pd.Series(['LOF', hazard_eval, non_hazard_eval], index=['model_name', 'TPR', 'TNR'])\n",
    "performance_df_ex = performance_df_ex.append(s, ignore_index = True)\n",
    "performance_df_ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9111912",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Save `performance_df_ex`, `non_hazard`, `test` and `actual_test` as pickle files `ex_performance_anomalies.sav`, `non_hazard.sav`, `test.sav` and `actual_test.sav` respectively for the following exercises.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(performance_df_ex, open(str(data_dir) + \"/ex_performance_anomalies.sav\",\"wb\" ))\n",
    "pickle.dump(non_hazard, open(str(data_dir) + \"/non_hazard.sav\",\"wb\" ))\n",
    "pickle.dump(test, open(str(data_dir) + \"/test.sav\",\"wb\" ))\n",
    "pickle.dump(actual_test, open(str(data_dir) + \"/actual_test.sav\",\"wb\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cdc67",
   "metadata": {},
   "source": [
    "## ANOMALY DETECTION PART 4 EXERCISE ANSWERS ##\n",
    "#### Exercise 3 ####\n",
    "#### Task 1\n",
    "##### Import the required packages\n",
    "##### Set the working directory to data directory\n",
    "##### Print the working directory and the plot directory\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e95823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# Set 'main_dir' to location of the project folder\n",
    "from pathlib import Path \n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1669c",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "##### Load pickled files from the previous exercises `ex_performance_anomalies.sav`, `non_hazard.sav`, `test.sav` and `actual_test.sav` as `performance_df_ex`, `non_hazard`, `test` and `actual_test` respectively.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df_ex = pickle.load(open((str(data_dir) + \"/ex_performance_anomalies.sav\"),\"rb\"))\n",
    "non_hazard = pickle.load(open((str(data_dir) + \"/non_hazard.sav\"),\"rb\"))\n",
    "test = pickle.load(open((str(data_dir) + \"/test.sav\"),\"rb\"))\n",
    "actual_test = pickle.load(open((str(data_dir) + \"/actual_test.sav\"),\"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961c1b4",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Load `PJM_Load_hourly.csv` dataset and print the head. Save as `pjm_load`.\n",
    "##### Convert `Datatime` variable from type `object` to `datetime`. Check its datatype after type-conversion\n",
    "##### Filter the data to include values post year 2000\n",
    "##### Visualize the timeseries data using a lineplot\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "pjm_load = pd.read_csv(str(data_dir)+\"/PJM_Load_hourly.csv\")\n",
    "pjm_load.head()\n",
    "pjm_load['Datetime'] = pd.to_datetime(pjm_load['Datetime'])\n",
    "pjm_load.info()\n",
    "pjm_load = pjm_load[pjm_load['Datetime'] > '2000-01-01 00:00:00']\n",
    "pjm_load.plot(x='Datetime', y='PJM_Load_MW', figsize=(17,6))\n",
    "plt.xlabel('Date time')\n",
    "plt.ylabel('Energy Consumption')\n",
    "plt.title('Energy consumption - Load combined (MW) at each hour')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0ada7",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Fit the LOF model with `n_neighbors: 100` , `contamination: 0.01`  and `novelty: False`\n",
    "##### Predict for anomalies for the variable `PJM_Load_MW` and save the results in the pjm_load dataframe\n",
    "##### Visualize the detected anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b03427",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_energy_model = LocalOutlierFactor(n_neighbors = 100, metric = \"manhattan\", contamination = 0.01, novelty = False)\n",
    "lof_energy_model.fit(pd.DataFrame(pjm_load['PJM_Load_MW']))\n",
    "pjm_load['anomaly'] = lof_energy_model.fit_predict(pd.DataFrame(pjm_load['PJM_Load_MW']))\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "a = pjm_load.loc[pjm_load['anomaly'] == -1, ['Datetime', 'PJM_Load_MW']] #anomaly\n",
    "ax.plot(pjm_load['Datetime'], pjm_load['PJM_Load_MW'], color='blue', label = 'Normal')\n",
    "ax.scatter(a['Datetime'],a['PJM_Load_MW'], color='red', label = 'Anomaly')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ca480",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Create variable `lof_upper_anomalies` that has the upper range of anomalies detected using the 75% quantile threshold\n",
    "##### Create variable `lof_lower_anomalies` that has the lower range of anomalies detected using the 25% quantile threshold\n",
    "##### Visualize `lof_upper_anomalies` and `lof_lower_anomalies`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_threshold = pjm_load['PJM_Load_MW'].quantile(0.25)\n",
    "upper_threshold = pjm_load['PJM_Load_MW'].quantile(0.75)\n",
    "lof_anomalies = pjm_load[pjm_load['anomaly'] == -1]\n",
    "# Upper range of anomalies\n",
    "lof_upper_anomalies = lof_anomalies[lof_anomalies['PJM_Load_MW'] > upper_threshold]['PJM_Load_MW']\n",
    "# Lower range of anomalies\n",
    "lof_lower_anomalies = lof_anomalies[lof_anomalies['PJM_Load_MW'] < lower_threshold]['PJM_Load_MW']\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.hist(lof_lower_anomalies)\n",
    "plt.xlabel(\"Anomaly points\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Lower range of anomalies\")\n",
    "plt.show()\n",
    "plt.hist(lof_upper_anomalies)\n",
    "plt.xlabel(\"Anomaly points\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Upper range of anomalies\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0775677",
   "metadata": {},
   "source": [
    "#### Exercise 4 ####\n",
    "#### Task 1\n",
    "##### Fit an isolation forest with 100 estimators and contamination: 0.1\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IsolationForest(n_estimators=100, contamination = 0.1)\n",
    "# model fitting\n",
    "iforest.fit(non_hazard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98f48e",
   "metadata": {},
   "source": [
    "#### Task 2 \n",
    "##### Predict on hazard test data and map the predictions as 0 for non-anomalies and 1 for anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9847107",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_pred = iforest.predict(test.iloc[:,:-1])\n",
    "hazard_pred[:5]\n",
    "hazard_pred[hazard_pred == 1] = 0\n",
    "hazard_pred[hazard_pred == -1] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3f374",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Evaluate the model using TPR and TNR\n",
    "##### Append the scores to the `performance_df_ex` dataframe\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(actual_test, hazard_pred).ravel()\n",
    "non_hazard_eval = tn / (tn + fp)\n",
    "print(non_hazard_eval)\n",
    "hazard_eval = tp / (tp + fn)\n",
    "print(hazard_eval)\n",
    "s = pd.Series(['Isolation Forest', hazard_eval, non_hazard_eval], \n",
    "              index=['model_name', 'TPR', 'TNR'])\n",
    "performance_df_ex = performance_df_ex.append(s, ignore_index = True)\n",
    "performance_df_ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3356da11",
   "metadata": {},
   "source": [
    "#### Exercise 5 ####\n",
    "#### Task 1\n",
    "##### Fit an isolation forest with 100 estimators and contamination: 0.01 on `pjm_load` time series data\n",
    "##### Predict for anomalies on `PJM_Load_MW` variable and save the results as a column in the pjm_load dataframe\n",
    "##### Visualize the detected anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolation_energy = IsolationForest(n_estimators=100, contamination = 0.01)\n",
    "# model fitting\n",
    "isolation_energy.fit(pd.DataFrame(pjm_load['PJM_Load_MW']))\n",
    "pjm_load['anomaly'] = isolation_energy.predict(pd.DataFrame(pjm_load['PJM_Load_MW']))\n",
    "# visualization\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "a = pjm_load.loc[pjm_load['anomaly'] == -1, ['Datetime', 'PJM_Load_MW']] #anomaly\n",
    "ax.plot(pjm_load['Datetime'], pjm_load['PJM_Load_MW'], color='blue', label = 'Normal')\n",
    "ax.scatter(a['Datetime'],a['PJM_Load_MW'], color='red', label = 'Anomaly')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849345d1",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Create variable `if_upper_anomalies` that has the upper range of anomalies detected using the 75% quantile threshold\n",
    "##### Create variable `if_lower_anomalies` that has the lower range of anomalies detected using the 25% quantile threshold\n",
    "##### Visualize `if_upper_anomalies` and `if_lower_anomalies`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "lower_threshold = pjm_load['PJM_Load_MW'].quantile(0.25)\n",
    "upper_threshold = pjm_load['PJM_Load_MW'].quantile(0.75)\n",
    "if_anomalies = pjm_load[pjm_load['anomaly'] == -1]\n",
    "if_upper_anomalies = if_anomalies[if_anomalies['PJM_Load_MW'] > upper_threshold]['PJM_Load_MW']\n",
    "if_lower_anomalies = if_anomalies[if_anomalies['PJM_Load_MW'] < lower_threshold]['PJM_Load_MW']\n",
    "plt.hist(if_lower_anomalies)\n",
    "plt.xlabel(\"Anomaly points\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Lower range of anomalies\")\n",
    "plt.show()\n",
    "plt.hist(if_upper_anomalies)\n",
    "plt.xlabel(\"Anomaly points\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Upper range of anomalies\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a615c",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Compare the anomalies detected from LOF and Isolation Forest\n",
    "##### Create a comparison plot for the lower range of anomalies\n",
    "##### Create a comparison plot for the upper range of anomalies\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lof_upper_anomalies,alpha = 0.5,label='LOF anomalies')\n",
    "plt.hist(if_upper_anomalies,alpha = 0.5,label='IF anomalies')\n",
    "plt.title('Upper range of anomalies')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "plt.hist(lof_lower_anomalies,alpha = 0.5,label='LOF anomalies')\n",
    "plt.hist(if_lower_anomalies,alpha = 0.5,label='IF anomalies')\n",
    "plt.title('Lower range of anomalies')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb86d9",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Save the `performance_df_ex` as a pickle file `ex_performance_anomalies.sav`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd00357",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(performance_df_ex, open(str(data_dir) + \"/ex_performance_anomalies.sav\",\"wb\" ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
