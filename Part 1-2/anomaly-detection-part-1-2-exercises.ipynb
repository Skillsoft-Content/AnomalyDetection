{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f75f7c5",
   "metadata": {},
   "source": [
    "## ANOMALY DETECTION PART 1 EXERCISE  ##\n",
    "#### Exercise 1 ####\n",
    "#### Task 1\n",
    "##### Import the required packages\n",
    "##### Set the working directory to data directory\n",
    "##### Print the working directory and the plot directory\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e441a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abecc120",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Read in `seismic-hazards.csv` to a new dataframe `hazard`.\n",
    "##### Read the documentation to understand the variables https://archive.ics.uci.edu/ml/datasets/seismic-bumps#\n",
    "##### Explore the dataset by printing its head, info and shape.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6594f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecd970b9",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### The target variable in this dataset is `class`.\n",
    "##### Print the value counts of the target and also check the percentage of the outlier class.\n",
    "##### Plot the distribution of the target.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718b7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "165bcc17",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Drop all the non-numerical columns and target variable `class`. Save this subset as `hazard_dbscan` and print its head.\n",
    "##### Check how many NAs are in each column and impute them with mean, if required.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f961e9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8eba815",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Scale `hazard_dbscan` using the `StandardScaler` function.\n",
    "##### Name the scaled dataframe as `hazard_dbscan_scaled`. \n",
    "##### Convert `hazard_dbscan_scaled` back to a Pandas dataframe and make sure that the column names are the same as before.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735263e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59821c7f",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Run the DBSCAN model on `ex_db`.\n",
    "##### For now, we set Ïµ to have a radius of 0.4.\n",
    "##### We set MinPts (min_samples in the function) to 5.\n",
    "##### What do those two parameters mean?\n",
    "##### Check how many clusters we have.\n",
    "##### How many outliers do you have?\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892aa4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b61d379b",
   "metadata": {},
   "source": [
    "#### Exercise 2 ####\n",
    "#### Task 1\n",
    "##### Idenify the optimal eps using NearestNeighbors().\n",
    "##### Set number of neighbors to be `10` and fit the model to `hazard_dbscan_scaled`\n",
    "##### Calculate the distances of every point with it's 10 closest neighbors\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb7228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a876466",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Calculate average distance for each point with its 10 neighbors and sort the distances\n",
    "##### Plot the sorted distances\n",
    "##### Zoom the plot by filtering the distances after index 2400 \n",
    "##### Find the optimal `eps` distance from the elbow plot\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1dde9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "411c1f3b",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Run a new DBSCAN analysis with the optimized parameters.\n",
    "##### Check the number of clusters.\n",
    "##### Assign the cluster results to `hazard_dbscan`. Replace the anomaly cluster points with `1` and rest cluster points to `0`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff792a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b0d8900",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Visualize the anomalies detected using a scatterplot\n",
    "##### Plot a scatterplot with `energy` and `maxenergy`\n",
    "##### Plot a scatterplot with `genergy` and `maxenergy`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c69cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83d504b5",
   "metadata": {},
   "source": [
    "## ANOMALY DETECTION PART 2 EXERCISE  ##\n",
    "#### Exercise 3 ####\n",
    "#### Task 1\n",
    "##### Import the required packages\n",
    "##### Set the working directory to data directory\n",
    "##### Print the working directory and the plot directory\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6ca88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e29af0",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Load the `PJM_Load_hourly.csv` dataset and print the head. Save as `pjm_load`.\n",
    "##### Convert the `Datatime` variable from type `object` to `datetime`. Check its datatype after type-conversion\n",
    "##### Filter the data to include values post-year 2000\n",
    "##### Visualize the time series data using a line plot\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a979599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "151f12a2",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Scale the variable `PJM_Load_MW` and save the dataset as `pjm_load `. \n",
    "##### Find the optimal eps value using the k-distance approach\n",
    "##### Set the number of neighbors in NearestNeighbors() to be 5.\n",
    "##### Zoom the plot for values after `17000`.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bdb55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5bbc58",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Apply the DBSCAN algorithm on `ex_pjm_energy_scaled` with `optimal eps` and `min_samples:5`.\n",
    "##### Visualize the anomalies.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa64b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ad4424",
   "metadata": {},
   "source": [
    "#### Exercise 4 ####\n",
    "#### Task 1\n",
    "##### Read in `seismic-hazards.csv` to a new dataframe `hazard`.\n",
    "##### Use the `hazard` dataset to prepare for decision tree modeling\n",
    "##### Drop the `id` column, convert the categorical variables to dummies, and append them to the original dataframe.\n",
    "##### The variables are: seismic, seismoacoustic, shift, and ghazard. Note that the values of these variables are already coded.\n",
    "##### Hint: Columns can be sent listed together in pd.get_dummies()\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765b219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39101238",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Separate the target as `y_ex` and other columns as `X_ex`.\n",
    "##### Separate training and test data as `X_train_ex`, `X_test_ex`, `y_train_ex`, `y_test_ex` with 70:30 partition and fit a DecisionTreeClassifier with `max_depth: 10`\n",
    "##### Set random seed to 1\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4c0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "684e554e",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Predict on the training and test datasets.\n",
    "##### Print the testing accuracy.\n",
    "##### Print the confusion matrix for training and test data.\n",
    "##### Find the percentage of accurate hazards on training and test data.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882901dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80fb4066",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Find TPR and TNR.\n",
    "##### Save the metric to a new performance dataframe with the name `performance_df_ex`.\n",
    "##### Interpret the results.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d9f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5074e93e",
   "metadata": {},
   "source": [
    "#### Exercise 5 ####\n",
    "#### Task 1\n",
    "##### Set random_state as 1 and create SMOTE samples to training dataset as `X_train_new_ex` and `y_train_new_ex` to balance the classes.\n",
    "##### Print the shape of the training data before resampling and after resampling.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0ae23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b74985",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Plot the target variable of the resampled dataset (`y_train_new_ex`)\n",
    "##### How are the data points distributed?\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c6bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a483df9",
   "metadata": {},
   "source": [
    "- The classes are balanced now after SMOTE resampling\n",
    "#### Task 3\n",
    "##### Fit the DecisionTree Classifer to the resampled dataset and predict on train and test data.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bb133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79cc5ffd",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Print the confusion matrix for training and test data.\n",
    "##### Analyze the result.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa011960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed15aa23",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Find the TPR and TNR and save the result.\n",
    "##### Compare the result to our baseline DecisionTree model and interpret.\n",
    "##### Optional: If you wish to run other classification algorithms and compare results then save the dataframe as a pickle. Make sure to give it a name differing from slides pickle.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c900e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
